{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hoja de trabajo 06\n",
    "*Redes neuronales*\n",
    "\n",
    "*Diego Morales | Alejandro Azurdia*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolución de la hoja de trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Análisis de Escalabilidad del Modelo\n",
    "\n",
    "### 1. Cambie el número de observaciones a 100,000. Explique qué es lo que ocurre en términos de:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. El tiempo de ejecución para resolver el problemas**\n",
    "**El tiempo de ejecución para resolver porblemas ha crecido considerablemente. Multiplicandose en algunas instancias mas de 10 veces. \n",
    "\n",
    "**2. El resultado final vs lo encontrado en clase: es igual, o diferente...¿porqué?**\n",
    "Aunque no es igual porque el ploteo es de muchos mas puntos, es parecido al resultado obtenido en clase y el comportamiento exhibido es parecido. \n",
    "\n",
    "Esto se evidencia la analizar los resultaods de los pesos y el sesgo:\n",
    "\n",
    "- pesos: [[ 2.00026532] [-2.99934318]]\n",
    "- segos: [4.32473635]\n",
    "\n",
    "\n",
    "\n",
    "**3. Las gráficas para representar los datos/resultados**\n",
    "Las gráficas están iguales, aunque tienen muchos mas datos. En específico las gráfica para resultados están mucho mas pobladas, pero se comportan de la misma forma. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cambie el número de observaciones a 1,000,000. Explique qué es lo que ocurre en términos de:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. El tiempo de ejecución para resolver el problemas**\n",
    "El tiempo de ejecución para resolver problemas se multiplicó aun mas que la vez pasada. Para obtener el resultado final, el tiempo de ejecución es de 5 segundos y el entrenamiento es de 4.1 segundos. Este tiempo es casi 10 veces más alto que el encontrado anteriormente. Esto tiene sentido, pues eran 10 veces más observaciones. \n",
    "\n",
    "**2. El resultado final vs lo encontrado en clase: es igual, o diferente...¿porqué?**\n",
    "El resultado sigue siendo igual, aunque aún mas poblado de datos. \n",
    "\n",
    "**3. Las gráficas para representar los datos/resultados**\n",
    "Las gráficas siguen representando el comportamiento esperado, de una recta a 45° sobre el eje. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Experimentación con la Tasa de Aprendizaje (Total: 25 puntos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ¿Qué ocurre con el tiempo de ejecución?**\n",
    "Se observó que entre más pequeña se hacía la tasa de aprendizaje, más tiempo era requerido para encontrar le resultado. \n",
    "\n",
    "**2. ¿Qué ocurre con la minimización de la pérdida?**\n",
    "Se observa que entre menor es la tasa de crecimiento, menor es el valor de la diferencia entre iteraciones de la pérdida. Al acercarse a valores cercanos al 0, lo que antes claramente exhibía un comportamiento exponencial, se convierte casi en una recta .\n",
    "\n",
    "**3. ¿Qué ocurre con los pesos y los sesgos?**\n",
    "Tanto los pesos como los sesgos no se ajustan correctamente al comportamiento esperado. Los pesos sufren modificaciones relativamente leves, mientras que el sesgo está completamente errado. Se espera un valor de 5 y se obtiene un valor de 0.39. \n",
    "\n",
    "**4. ¿Qué ocurre con las iteraciones?**\n",
    "Las iteraciones no sufren modificaciones. El tiempo de ejecución también es el mismo. \n",
    "\n",
    "**5. ¿El problema queda resuelto o no?**\n",
    "El problema parece quedar resuelto ya que se aprecia una recta 45° como resultado del ploteo, aún con el desajuste de los sesgos, sin embargo un análisis mas profundo es requerido para confirmar este resultado. \n",
    "\n",
    "**¿Cuál es la apariencia de la última gráfica? ¿Se cumple con la condición de que sea de 45 grados?**\n",
    "Sí, se cumple la condición de que esté a 45°. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Modificación de la Función de Pérdida (Total: 25 puntos)\n",
    "#### Cambie la función de pérdida “L2-norm” a la misma pero sin dividir por 2. Explique lo que ocurre en términos de:\n",
    "**1. El tiempo que se tarda el algoritmo en terminar, comparado a lo que vimos en clase**\n",
    "El tiempo que tarda el algoritmo no cambia significativamente con este cambio.\n",
    "\n",
    "**2. Si la pérdida se minimiza igual que lo que vimos en clase**\n",
    "    La pérdida inicial es mucho más alta que en el caso anterior. Sin embargo, también disminuye con cada iteración, aunque a un ritmo más lento. La pérdida sigue disminuyendo, pero parece que el algoritmo necesita más iteraciones para converger hacia una solución.\n",
    "\n",
    "**3. Si los pesos y sesgos son parecidos a los vistos en clase**\n",
    "- Pesos: Los valores de los pesos son ligeramente diferentes antes y después del cambio en la función de pérdida. Sin embargo, ambos conjuntos de pesos están cerca de los valores esperados (2 y -3) para resolver el problema de regresión lineal.\n",
    "- Sesgo: El sesgo también muestra una ligera diferencia entre antes y después del cambio. Al igual que con los pesos, ambos valores de sesgo están cerca del valor esperado (5).\n",
    "\n",
    "**4. Si el problema se resuelve como ocurrió en clase**\n",
    "El problema aún se resuelve utilizando el mismo enfoque de regresión lineal con descenso de gradiente. Sin embargo, la velocidad y la precisión pueden verse afectadas por el cambio en la función de pérdida.\n",
    "\n",
    "**5. Si se obtiene un mejor resultado al hacer más iteraciones**\n",
    "Se observa que la pérdida disminuye a medida que aumentan las iteraciones. Inicialmente, la pérdida es alta (492.57), pero disminuye rápidamente con las iteraciones, alcanzando valores muy bajos alrededor de 0.32 después de 10,000 iteraciones. Esto indica que el modelo está convergiendo hacia un mínimo de pérdida, lo que sugiere que sí se obtiene un mejor resultado al hacer más iteraciones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cambie la función de pérdida de la “L2-norm” a “L1-norm”. Explique lo que ocurre en términos de:\n",
    "**1. El tiempo que se tarda el algoritmo en terminar, comparado a lo que vimos en clase**\n",
    "El tiempo que tarda el algoritmo no cambia significativamente con este cambio.\n",
    "\n",
    "**2. Si la pérdida se minimiza igual que lo que vimos en clase**\n",
    "La pérdida se minimiza de manera diferente con L1-norm y L2-norm porque utilizan diferentes formas de calcular el error entre las predicciones del modelo y los valores reales. L2-norm calcula la suma de los cuadrados de las diferencias, mientras que L1-norm calcula la suma de las diferencias absolutas.\n",
    "\n",
    "**3. Si los pesos y sesgos son parecidos a los vistos en clase**\n",
    "Estos valores son muy similares a los obtenidos con L1-norm. Parece que el cambio en la función de pérdida no afectó significativamente los valores finales de los pesos y sesgos.\n",
    "\n",
    "**4. Si el problema se resuelve como ocurrió en clase**\n",
    "No, el problema no se resolverá exactamente de la misma manera. Al cambiar la función de pérdida de L2-norm a L1-norm, la forma en que se penalizan las discrepancias entre las predicciones y las metas durante el entrenamiento del modelo será diferente. La L2-norm penaliza más fuertemente las grandes discrepancias, mientras que la L1-norm penaliza todas las discrepancias por igual.\n",
    "\n",
    "**5. Si se obtiene un mejor resultado al hacer más iteraciones**\n",
    "Al realizar 10,000 interaciones el resultado de la perdida final disminuyó en 0.20. Se obtuvo un mejor resultado pero no tan grande como con L2-norm.\n",
    "\n",
    "**6. ¿Tendrá una de estas más limitaciones que la otra?**\n",
    "La L2-norm puede ser sensible a valores atípicos debido a la forma en que penaliza las discrepancias al cuadrado, lo que puede llevar a un modelo menos robusto en presencia de datos atípicos. Por otro lado, la L1-norm puede ser más robusta a los valores atípicos ya que penaliza las discrepancias de manera lineal, pero puede tener dificultades para encontrar soluciones óptimas en problemas donde hay múltiples soluciones óptimas o cuando las características son altamente correlacionadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Cree una función f(x1, x2) = 13 * x1 + 7 * x2 - 12\n",
    "#### ¿Funciona el algoritmo de la misma forma?\n",
    "El algoritmo seguirá funcionando de la misma forma, ya que simplemente se está ajustando los valores de las metas (objetivos) para que se correspondan con esta nueva función. El cambio en la función objetivo no afecta el proceso de entrenamiento del modelo de regresión lineal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
